{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finetune.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok440ey5qnb1"
      },
      "source": [
        "# Sakamoto BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98NOgl11vveW"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_SY2z6yPzsR"
      },
      "source": [
        "install Transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n8sEYakyjpw",
        "outputId": "96fc0b78-2647-4423-e0c7-f0fb8723db28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
            "\r\u001b[K     |▎                               | 10kB 21.6MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 4.1MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 4.4MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 4.1MB/s eta 0:00:01\r\u001b[K     |█▉                              | 71kB 4.5MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 4.8MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92kB 5.1MB/s eta 0:00:01\r\u001b[K     |██▋                             | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |██▉                             | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▏                            | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 163kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▍                           | 174kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▊                           | 184kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 194kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 204kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 215kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 225kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 235kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 245kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 256kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 266kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 276kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 286kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 296kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 307kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 317kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 327kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 337kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 348kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 358kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 368kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 378kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 389kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 399kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 409kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 419kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 430kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 440kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 450kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 460kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 471kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 481kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 491kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 501kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 512kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 522kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 532kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 542kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 552kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 563kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 573kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 583kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 593kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 604kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 614kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 624kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 634kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 645kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 655kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 665kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 675kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 686kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 696kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 706kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 716kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 727kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 737kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 747kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 757kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 768kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 778kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 788kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 798kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 808kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 819kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 829kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 839kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 849kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 860kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 870kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 880kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 890kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 901kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 911kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 921kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 931kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 942kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 952kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 962kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 972kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 983kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 993kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.0MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 28.3MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 40.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers==0.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 50.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=c1e5ca9c37a5891573fb82d151b6d7ac39dfe727517cb80fc023063015f1d2c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.9.2 transformers-3.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52OMOpp4tATI"
      },
      "source": [
        "download the BERT Japanese pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf5d3JaoqNr7",
        "outputId": "ef01087f-e800-46d4-9d84-911262f9415a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget http://nlp.ist.i.kyoto-u.ac.jp/nl-resource/JapaneseBertPretrainedModel/Japanese_L-12_H-768_A-12_E-30_BPE_WWM_transformers.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-08 01:05:18--  http://nlp.ist.i.kyoto-u.ac.jp/nl-resource/JapaneseBertPretrainedModel/Japanese_L-12_H-768_A-12_E-30_BPE_WWM_transformers.zip\n",
            "Resolving nlp.ist.i.kyoto-u.ac.jp (nlp.ist.i.kyoto-u.ac.jp)... 133.242.249.182\n",
            "Connecting to nlp.ist.i.kyoto-u.ac.jp (nlp.ist.i.kyoto-u.ac.jp)|133.242.249.182|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 411210545 (392M) [application/zip]\n",
            "Saving to: ‘Japanese_L-12_H-768_A-12_E-30_BPE_WWM_transformers.zip’\n",
            "\n",
            "Japanese_L-12_H-768 100%[===================>] 392.16M  18.8MB/s    in 22s     \n",
            "\n",
            "2020-11-08 01:05:41 (17.5 MB/s) - ‘Japanese_L-12_H-768_A-12_E-30_BPE_WWM_transformers.zip’ saved [411210545/411210545]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW5MTP4HvAEk",
        "outputId": "59fa4033-bdf8-4b35-fcc8-19af4a13979e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!unzip Japanese_L-12_H-768_A-12_E-30_BPE_WWM_transformers.zip -d bert"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  Japanese_L-12_H-768_A-12_E-30_BPE_WWM_transformers.zip\n",
            "   creating: bert/Japanese_L-12_H-768_A-12_E-30_BPE_WWM_transformers/\n",
            "  inflating: bert/Japanese_L-12_H-768_A-12_E-30_BPE_WWM_transformers/pytorch_model.bin  \n",
            "  inflating: bert/Japanese_L-12_H-768_A-12_E-30_BPE_WWM_transformers/vocab.txt  \n",
            "  inflating: bert/Japanese_L-12_H-768_A-12_E-30_BPE_WWM_transformers/config.json  \n",
            "  inflating: bert/Japanese_L-12_H-768_A-12_E-30_BPE_WWM_transformers/tokenizer_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KgFeuTjoU7i"
      },
      "source": [
        "copy Sakamoto SST-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz4lZhZet20r"
      },
      "source": [
        "!cp -r drive/My\\ Drive/sakamoto-bert/SST-2 sakamoto_sst2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROJKeU4ev3Mi"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCZTi7Qe_Ur4"
      },
      "source": [
        "clone the repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfc7KcJHzwKo",
        "outputId": "7e2c53d1-78d1-486b-b3a3-69715c12a613",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 50085 (delta 1), reused 1 (delta 0), pack-reused 50074\u001b[K\n",
            "Receiving objects: 100% (50085/50085), 36.95 MiB | 27.42 MiB/s, done.\n",
            "Resolving deltas: 100% (34957/34957), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kSf4cG-vARX",
        "outputId": "05c47f4f-d4d8-4ee0-8f68-5fda6962979b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd transformers\n",
        "!git checkout bb9559a7f98fc18747fd957c3bd2a6e4c1111e45\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/transformers\n",
            "Note: checking out 'bb9559a7f98fc18747fd957c3bd2a6e4c1111e45'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at bb9559a7 Don't use `store_xxx` on optional bools (#7786)\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Yz3FiaDqA-m"
      },
      "source": [
        "fine-tune the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVgKfjQawoSW",
        "outputId": "7fad58c5-5b73-4ef8-fac4-27d4863f8752",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python transformers/examples/text-classification/run_glue.py \\\n",
        "    --model_name_or_path bert/Japanese_L-12_H-768_A-12_E-30_BPE_WWM_transformers \\\n",
        "    --task_name SST-2 \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --data_dir sakamoto_sst2 \\\n",
        "    --max_seq_length 128 \\\n",
        "    --per_device_train_batch_size 32 \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --num_train_epochs 3.0 \\\n",
        "    --output_dir bert_sakamoto_sst2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-08 01:05:59.507562: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "11/08/2020 01:06:01 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "11/08/2020 01:06:01 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='bert_sakamoto_sst2', overwrite_output_dir=False, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=2e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Nov08_01-06-01_67b01f7980bb', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='bert_sakamoto_sst2', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None)\n",
            "Some weights of the model checkpoint at bert/Japanese_L-12_H-768_A-12_E-30_BPE_WWM_transformers were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert/Japanese_L-12_H-768_A-12_E-30_BPE_WWM_transformers and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "11/08/2020 01:06:05 - INFO - filelock -   Lock 140580649493896 acquired on sakamoto_sst2/cached_train_BertTokenizer_128_sst-2.lock\n",
            "11/08/2020 01:06:07 - INFO - filelock -   Lock 140580649493896 released on sakamoto_sst2/cached_train_BertTokenizer_128_sst-2.lock\n",
            "11/08/2020 01:06:07 - INFO - filelock -   Lock 140580641960176 acquired on sakamoto_sst2/cached_dev_BertTokenizer_128_sst-2.lock\n",
            "11/08/2020 01:06:07 - INFO - filelock -   Lock 140580641960176 released on sakamoto_sst2/cached_dev_BertTokenizer_128_sst-2.lock\n",
            "100% 450/450 [05:13<00:00,  1.43it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/trainer.py:1118: FutureWarning: This method is deprecated, use `Trainer.is_world_process_zero()` instead.\n",
            "  warnings.warn(\"This method is deprecated, use `Trainer.is_world_process_zero()` instead.\", FutureWarning)\n",
            "11/08/2020 01:11:37 - INFO - __main__ -   *** Evaluate ***\n",
            "100% 17/17 [00:01<00:00, 14.27it/s]11/08/2020 01:11:38 - INFO - __main__ -   ***** Eval results sst-2 *****\n",
            "11/08/2020 01:11:38 - INFO - __main__ -     eval_loss = 0.30277326703071594\n",
            "11/08/2020 01:11:38 - INFO - __main__ -     eval_acc = 0.9037037037037037\n",
            "11/08/2020 01:11:38 - INFO - __main__ -     epoch = 3.0\n",
            "11/08/2020 01:11:38 - INFO - __main__ -     total_flos = 1217800017146880\n",
            "100% 17/17 [00:01<00:00, 14.67it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zbL0W_Bxfps"
      },
      "source": [
        "copy the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUuMg0rNw_dW"
      },
      "source": [
        "!cp -r bert_sakamoto_sst2 drive/My\\ Drive/sakamoto-bert/model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J8uICRa5n3t"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMIleRijDl9-"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjAXSOsX7mqT"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('bert_sakamoto_sst2')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('bert_sakamoto_sst2', return_dict=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Yx2wS09oNg9"
      },
      "source": [
        "classes = ['not sksk_sskn', 'is sksk_sskn']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlOF-Bd5-Tes"
      },
      "source": [
        "import csv\n",
        "\n",
        "sequences = []\n",
        "with open('sakamoto_sst2/test.tsv', newline='') as f:\n",
        "    reader = csv.DictReader(f, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
        "    for row in reader:\n",
        "        sequences.append(row['sentence'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJUIrVZ_Aw-n",
        "outputId": "21f9801d-05f7-4da9-d40c-5f408ff5fe86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for sequence in sequences:\n",
        "    sequence_tensor = tokenizer(sequence, return_tensors='pt')\n",
        "    classification_logits = model(**sequence_tensor).logits\n",
        "    results = torch.softmax(classification_logits, dim=1).tolist()[0]\n",
        "\n",
        "    print(sequence)\n",
        "    for i in range(len(classes)):\n",
        "        print(f'{classes[i]}: {results[i] * 100}%')\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "母 に ハンネ で 呼ば れた ので スマホ 食った\n",
            "not sksk_sskn: 99.69808459281921%\n",
            "is sksk_sskn: 0.30191761907190084%\n",
            "\n",
            "午後 の 紅茶 が 美味し すぎて 口 の 形 が ペットボトル に なっちゃ った ……\n",
            "not sksk_sskn: 44.24114227294922%\n",
            "is sksk_sskn: 55.75885772705078%\n",
            "\n",
            "ざむ ちゃん 実は 戦隊 モノ の 黄色 を 担当 して いる んだ よ ね\n",
            "not sksk_sskn: 5.700467526912689%\n",
            "is sksk_sskn: 94.29953098297119%\n",
            "\n",
            "アタシ 、 大きく なったら ナン に なる の が 夢 だった んだ 、 母 が なり たくて も なれ なかった もの だ から …\n",
            "not sksk_sskn: 98.44356775283813%\n",
            "is sksk_sskn: 1.556432619690895%\n",
            "\n",
            "来年 サカ ちゃん カレンダー 開催 し ます ので 覚悟 して おいて ください ね\n",
            "not sksk_sskn: 99.71803426742554%\n",
            "is sksk_sskn: 0.28196333441883326%\n",
            "\n",
            "こんにちは 、 ” 坂本 ” … です … 　 ピキキ … （ メガネ が 割れる 音 ） 　 タスケテーッッッタスケテーッッッタスケテーッッッタスケテーッッッタスケテーッッッタスケテーッッッタスケテーッッッタスケテーッッッタスケテーッッッタスケテーッッッタスケテーッッッ 　 タスケテーッッッ 　 それ で は 、 さようなら\n",
            "not sksk_sskn: 60.26184558868408%\n",
            "is sksk_sskn: 39.73815739154816%\n",
            "\n",
            "外 寒 すぎて デッケェ 冷え ピタ に 包ま れた とき と 全く 同じ 気持ち に なった\n",
            "not sksk_sskn: 99.61721301078796%\n",
            "is sksk_sskn: 0.38279134314507246%\n",
            "\n",
            "口 に 入れた 梅干し が 想像 以上 に スッパ くて この世 が 一 点 に 圧縮 さ れた\n",
            "not sksk_sskn: 98.90459179878235%\n",
            "is sksk_sskn: 1.095407921820879%\n",
            "\n",
            "密度 が 高 すぎる ため 少量で 胃 の 質量 を ５０００ 倍 に し 人間 を 内側 から 破壊 する 餅 と いう 食材 、 本当に 面白い\n",
            "not sksk_sskn: 98.99572730064392%\n",
            "is sksk_sskn: 1.004269253462553%\n",
            "\n",
            "これ が …… …… モチ …… …… ！ ？\n",
            "not sksk_sskn: 90.66720604896545%\n",
            "is sksk_sskn: 9.332790970802307%\n",
            "\n",
            "最後の 肉まん を 救い 出そう と したら 、 他 の 人 に 先 に 救い 出さ れて しまい 美味しく 食べ られろ よ な … と なった\n",
            "not sksk_sskn: 90.17797112464905%\n",
            "is sksk_sskn: 9.822031855583191%\n",
            "\n",
            "手袋 する と 指 パッチン が 出来 なく なっちゃ う んだ よ ネ …\n",
            "not sksk_sskn: 99.42203760147095%\n",
            "is sksk_sskn: 0.5779602564871311%\n",
            "\n",
            "Ｌｖ ９ の ヨッシー に なり がち\n",
            "not sksk_sskn: 2.2807076573371887%\n",
            "is sksk_sskn: 97.71929383277893%\n",
            "\n",
            "私 が 私 である こと を 信じて る から こそ 私 は …… すみません …… 本当 は 私 ざむ ちゃん です\n",
            "not sksk_sskn: 77.07839012145996%\n",
            "is sksk_sskn: 22.92160540819168%\n",
            "\n",
            "この はんぺん と か いう ヤツ 、 おもしろい から つゆ だく に しちゃ おう ね\n",
            "not sksk_sskn: 1.5708951279520988%\n",
            "is sksk_sskn: 98.42910766601562%\n",
            "\n",
            "自室 で フィギュア を 見て おほほ と 笑った 話\n",
            "not sksk_sskn: 7.416819781064987%\n",
            "is sksk_sskn: 92.58317947387695%\n",
            "\n",
            "君 は 私 の 手 に は 負え ない よ …… トホホ …… と 思わ せて くれる 担当 、 好きです\n",
            "not sksk_sskn: 5.265425145626068%\n",
            "is sksk_sskn: 94.73457336425781%\n",
            "\n",
            "傘 を 忘れた ので カエル に なった ゲコッ\n",
            "not sksk_sskn: 15.723828971385956%\n",
            "is sksk_sskn: 84.27616953849792%\n",
            "\n",
            "すれ違った サラリーマン 達 が みかん 狩り の 話 を して いて ニコニコ に なった\n",
            "not sksk_sskn: 99.60901141166687%\n",
            "is sksk_sskn: 0.3909854218363762%\n",
            "\n",
            "麺 に ” 真剣 ” な ので 麺 を 食べる 時 の 「 いただき ます 」 に は どうしても 気合 が 入って しまって 空手 家 みたいに なっちゃ う ワネ\n",
            "not sksk_sskn: 96.54185771942139%\n",
            "is sksk_sskn: 3.458143398165703%\n",
            "\n",
            "雨 、 さんさんと この 身 に 落ちて しまい 私 は ……\n",
            "not sksk_sskn: 43.40104162693024%\n",
            "is sksk_sskn: 56.598955392837524%\n",
            "\n",
            "世界 中 の 推し たち が 目の前 に 集まって 会話 して いる の を 眺めて いたら 感情 を 手 に 入れて 「 これ が …… 心ッ …… ！ ？ 」 と 叫んで 起き ました 　 良き 夢 だった な\n",
            "not sksk_sskn: 97.11576104164124%\n",
            "is sksk_sskn: 2.884242497384548%\n",
            "\n",
            "この メロン パン 、 実は 生きて る んです よ ね ……\n",
            "not sksk_sskn: 29.113659262657166%\n",
            "is sksk_sskn: 70.88633179664612%\n",
            "\n",
            "致死 量 の 龍角散 を 粉々に し たい 気持ち\n",
            "not sksk_sskn: 99.13033246994019%\n",
            "is sksk_sskn: 0.8696696721017361%\n",
            "\n",
            "量 を 重要 視 した ” 食 ” を 行う に あたって 障害 と さ れる 熱 と 冷え は 取り除く と いい らしい です ワザップ に よる と\n",
            "not sksk_sskn: 98.45494031906128%\n",
            "is sksk_sskn: 1.5450607053935528%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPUb7qdNVPSq"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqmY3OCDxAhS"
      },
      "source": [
        "Transformers\n",
        "\n",
        "- [transformers/examples/text-classification at master · huggingface/transformers](https://github.com/huggingface/transformers/tree/master/examples/text-classification)\n",
        "- [Summary of the tasks — transformers 3.0.2 documentation](https://huggingface.co/transformers/task_summary.html#sequence-classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajvro66ztMFn"
      },
      "source": [
        "BERT Japanese Pretrained Model\n",
        "\n",
        "- [BERT日本語Pretrainedモデル - KUROHASHI-CHU-MURAWAKI LAB](http://nlp.ist.i.kyoto-u.ac.jp/index.php?BERT%E6%97%A5%E6%9C%AC%E8%AA%9EPretrained%E3%83%A2%E3%83%87%E3%83%AB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OXimgQCf5L0"
      },
      "source": [
        "The Stanford Sentiment Treebank\t\n",
        "\n",
        "- [GLUE Benchmark](https://gluebenchmark.com/tasks)"
      ]
    }
  ]
}